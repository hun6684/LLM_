{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMD1n2y7yh8TeBHxiu6/tSF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hun6684/LLM_/blob/main/%EC%A7%80%EB%8A%A5%ED%98%95_12%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o22eg3u3quBF"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_zNYuoLrqPw",
        "outputId": "f9fda6d2-a352-4042-bd8e-9580e71024d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.12/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "max_retries = 3\n",
        "retry_delay = 5 # seconds"
      ],
      "metadata": {
        "id": "oCc1Vwk7q2d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "          {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "          {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "        ],\n",
        "        max_tokens = 200\n",
        "    )\n",
        "\n",
        "\n",
        "    print (response.choices [0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error.APIError as e:\n",
        "    print (f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries - 1:\n",
        "      print(f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "    else:\n",
        "      print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXUD2X2Hq_Ov",
        "outputId": "d7c7ed4d-9cb4-4b3f-b9a6-ab14f8512504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동은 건강에 많은 이점을 제공합니다. 그 중 일부를 나열해 봅시다:\n",
            "\n",
            "1. 체중 관리 - 운동은 칼로리를 소모하므로 체중을 줄이거나 관리하는데 도움이 됩니다.\n",
            "\n",
            "2. 심장 건강 향상 - 운동은 심장을 강하게 만들고 혈압을 낮추는데 도움이 됩니다. 이는 심장병과 뇌졸중을 예방하는데 기여합니다.\n",
            "\n",
            "3. 당뇨병 예방 - 운동은 당뇨병을 예방하거나 관리하는 데\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "\n",
        "      max_tokens = 200\n",
        "    )\n",
        "\n",
        "    print(response.choices [0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error.APIError as e:\n",
        "    print(f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries-1:\n",
        "      print(f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "  else:\n",
        "    print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RML-A6J0r5Nx",
        "outputId": "8219a99a-17c6-493a-fc57-1c0ca28d1d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동의 건강에 대한 이점은 다음과 같습니다:\n",
            "\n",
            "1. 체중 관리: 운동은 칼로리를 소모함으로써 체중을 관리하고, 비만을 예방하는 데 도움이 됩니다.\n",
            "\n",
            "2. 심장 건강: 정기적인 운동은 심장을 건강하게 유지하는 데 중요한 역할을 합니다. 이는 고혈압, 심장 질환, 뇌졸중 등의 위험을 감소시키는 데 도움이 됩니다.\n",
            "\n",
            "3. 정신 건강: 운동은 스트레스를 줄이고, 우울\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "\n",
        "      temperature=0.1\n",
        "    )\n",
        "\n",
        "    print(response.choices [0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error.APIError as e:\n",
        "    print(f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries-1:\n",
        "      print(f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "  else:\n",
        "    print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVncW9YEsrzc",
        "outputId": "e6b9a316-5620-4772-8479-75829f80430f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동은 건강에 다양한 이점을 제공합니다. \n",
            "\n",
            "1. 체중 관리: 운동은 칼로리를 소모하므로 체중 감소 또는 체중 관리에 도움이 됩니다.\n",
            "\n",
            "2. 질병 예방: 운동은 심장 질환, 고혈압, 당뇨병, 일부 암 종류 등 다양한 건강 문제의 위험을 줄일 수 있습니다.\n",
            "\n",
            "3. 기분 개선: 운동은 스트레스를 줄이고, 우울증과 불안을 완화하며, 자신감을 향상시키는 데 도움이 됩니다.\n",
            "\n",
            "4. 에너지 향상: 정기적인 운동은 근육력을 향상시키고 체력을 높여 일상 생활의 활동을 더 쉽게 수행할 수 있게 합니다.\n",
            "\n",
            "5. 수면 향상: 운동은 수면의 질을 향상시키고, 수면 문제를 겪고 있는 사람들에게 도움이 될 수 있습니다.\n",
            "\n",
            "6. 뼈 및 근육 건강: 운동은 뼈 밀도를 유지하고, 근육을 강화하며, 관절 유연성을 향상시킵니다.\n",
            "\n",
            "이러한 이유로, 건강한 생활 습관을 유지하려면 정기적인 운동을 포함하는 것이 중요합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "\n",
        "      temperature=0.9\n",
        "    )\n",
        "\n",
        "    print(response.choices [0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error.APIError as e:\n",
        "    print(f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries-1:\n",
        "      print(f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "  else:\n",
        "    print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C87yJhu0s13_",
        "outputId": "e09067c2-eb26-40e0-8242-ba03e573feac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동의 건강 이점은 다음과 같습니다:\n",
            "\n",
            "1. 체중 관리: 운동은 칼로리 소비를 증가시켜 체중 감량에 도움을 줍니다.\n",
            "2. 심장 건강 향상: 운동은 심장과 혈관을 강화하며, 심장 질환의 위험을 줄입니다.\n",
            "3. 내구성 강화: 꾸준한 운동은 근육의 내구성을 높여 일상생활의 활동을 보다 쉽게 수행할 수 있게 합니다.\n",
            "4. 정신 건강 개선: 운동은 스트레스 감소, 우울증 완화 그리고 불안감을 줄이는데 도움을 줍니다.\n",
            "5. 자기 자신에 대한 자신감 향상: 지속적인 운동은 체형 개선과 근육 톤을 향상시켜 자신감을 증가시킵니다.\n",
            "6. 수면 향상: 운동은 더 나은 수면의 질을 촉진하고, 수면 장애를 일으키는 스트레스를 줄입니다.\n",
            "7. 에너지 레벨 향상: 꾸준한 운동은 체력을 높여 에너지 레벨을 향상시킵니다.\n",
            "8. 만성질환 위험 감소: 정기적인 운동은 고혈압, 당뇨병, 일부 암 종류 등의 만성질환 위험을 줄입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for attempt in range(max_retries):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "      ],\n",
        "\n",
        "      seed=42\n",
        "    )\n",
        "\n",
        "    print(response.choices [0].message['content'])\n",
        "    break # Exit the loop if successful\n",
        "  except openai.error.APIError as e:\n",
        "    print(f\"API error occurred: {e}\")\n",
        "    if attempt < max_retries-1:\n",
        "      print(f\"Retrying in {retry_delay} seconds...\")\n",
        "      time.sleep(retry_delay)\n",
        "  else:\n",
        "    print(\"Max retries reached. Giving up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J57kSouAs8EY",
        "outputId": "998e9855-fad9-4a69-f927-2084c0a78ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정기적인 운동의 건강 이점은 많습니다. \n",
            "\n",
            "1. 체중감량: 운동은 칼로리를 소모시켜 체중 감량을 도울 수 있습니다.\n",
            "2. 심장 질환 예방: 운동은 고혈압, 심장질환 등을 예방하는데 도움이 됩니다.\n",
            "3. 기분 개선: 운동을 하면 뇌에서 '행복 화학물질'인 엔돌핀이 분비되어 기분을 좋게 합니다.\n",
            "4. 에너지 향상: 정기적인 운동은 체력을 향상시키고 에너지를 높여줍니다.\n",
            "5. 잠 잘 자기: 규칙적인 운동은 깊고 편안한 잠을 잘 수 있도록 돕습니다.\n",
            "6. 강력한 면역 시스템: 운동은 면역체계를 강화시켜서, 감기와 같은 일반적인 질병을 예방하는데 도움이 됩니다.\n",
            "7. 뼈 및 근육 강화: 운동, 특히 저항 훈련 및 가중치 베어링 활동은 뼈 및 근육 강화에 도움이 됩니다.\n",
            "\n",
            "이것은 단지 몇 가지 예일 뿐이며, 정기적인 운동이 걸치게 될 수 있는 다양한 질병과 건강 문제를 예방하는데 큰 도움이 됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "# Function to get embeddings for a list of texts using OpenAI Embeddings API\n",
        "def get_embeddings(texts):\n",
        "  response = openai.Embedding.create(\n",
        "    input=texts,\n",
        "    model=\"text-embedding-ada-002\" # You can replace this with other available models\n",
        "  )\n",
        "\n",
        "    # Extract and return the embeddings\n",
        "  return [embedding['embedding'] for embedding in response['data']]"
      ],
      "metadata": {
        "id": "7Kxda8wetCVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of color words to embed\n",
        "color_words = [\"red\", \"blue\", \"yellow\", \"green\", \"violet\", \"cyan\", \"black\", \"white\"]\n",
        "\n",
        "# Get embeddings for the color words\n",
        "color_embeddings = get_embeddings(color_words)\n",
        "\n",
        "# Print the embeddings for each color word\n",
        "for word, embedding in zip(color_words, color_embeddings):\n",
        "  print(f\"{word}: {embedding[:5]}...\") # Print only the first 5 dimensions for brevity\n",
        "  print(len (embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzIqApsq_QO",
        "outputId": "b64d52a3-bdc1-42d4-e411-7ed26359e5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "red: [9.326533472631127e-06, -0.02476814016699791, -0.002384250983595848, -0.028791459277272224, -0.021199282258749008]...\n",
            "1536\n",
            "blue: [0.005474964156746864, -0.007486246060580015, 0.005678507499396801, -0.03110414557158947, -0.01965053379535675]...\n",
            "1536\n",
            "yellow: [0.007661858107894659, -0.024910997599363327, 0.004491548519581556, -0.02860249951481819, -0.01958620548248291]...\n",
            "1536\n",
            "green: [0.01546180434525013, -0.010975971817970276, 0.025183379650115967, -0.02092933841049671, -0.005648194346576929]...\n",
            "1536\n",
            "violet: [-0.006727131083607674, -0.018318135291337967, 0.0036361967213451862, -0.00567674869671464, -0.021194979548454285]...\n",
            "1536\n",
            "cyan: [0.021550633013248444, -0.014010688289999962, 0.008289773017168045, -0.02929886430501938, -0.016149088740348816]...\n",
            "1536\n",
            "black: [-0.015103082172572613, -0.031215764582157135, 0.00877943355590105, -0.03691864386200905, -0.01613996922969818]...\n",
            "1536\n",
            "white: [0.006292110309004784, -0.02457117661833763, 0.0002028137823799625, -0.014848269522190094, -0.0052642603404819965]...\n",
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "CYweRAfStS-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload the dataset\n",
        "response = openai.File.create(\n",
        "    file = open(\"/content/mydata.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "\n",
        "file_id = response['id']\n",
        "print(f\"Uploaded file ID: {file_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HROAWCPutXEv",
        "outputId": "4c0f8a68-3875-4132-bf5b-047f6e0898e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file ID: file-BPnc2tj7vxBDL5hG9YZDxE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=''"
      ],
      "metadata": {
        "id": "ZKPGY-KEuyXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVJNeAhVusky",
        "outputId": "2b7ae299-0dc2-4816-e610-f6c659eee8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "from openai import OpenAI\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "P1eIpMvowGj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\"\n",
        "# Step 1: Upload the dataset\n",
        "with open(\"/content/mydata.jsonl\", \"rb\") as f:\n",
        "    response = client.files.create(\n",
        "        file=f,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "file_id = response.id\n",
        "print(\"Uploaded file ID:\", file_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duPlkMU8v_kr",
        "outputId": "c707d244-9908-428c-a88b-cb0527cd83e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file ID: file-1pmpzB2cmeBN9QuDn9kLwr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Step 2: Create a fine-tuning job\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-4o-mini-2024-07-18\"\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Fine-tune job ID:\", response.id)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tNUyTDZt_6b",
        "outputId": "6a953166-adab-47a6-e21b-f400e7bc7910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune job ID: ftjob-bDn12IAtDEfENwt8fWeUBOzb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "fine_tune_id = \"ftjob-bDn12IAtDEfENwt8fWeUBOzb\"\n",
        "\n",
        "# Step 3: Monitor the fine-tuning job\n",
        "while True:\n",
        "    job = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "    status = job.status\n",
        "    print(f\"Fine-tune job status: {status}\")\n",
        "\n",
        "    if status in [\"succeeded\", \"failed\"]:\n",
        "        print(\"Fine-tuning completed!\")\n",
        "        break\n",
        "\n",
        "    time.sleep(60) # Wait 60 seconds before checking the status again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbEYITbKxCl0",
        "outputId": "bcb97884-a2bd-4fee-d812-7111c43bcc4a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune job status: validating_files\n",
            "Fine-tune job status: validating_files\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: running\n",
            "Fine-tune job status: succeeded\n",
            "Fine-tuning completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "if status == 'succeeded':\n",
        "    # Step 4: Use the fine-tuned model\n",
        "    response = client.completions.create(\n",
        "        model=fine_tune_id,  # fine-tuned model ID\n",
        "        prompt=\"Translate the following English text to French: 'Good night'\",\n",
        "        max_tokens=50\n",
        "    )\n",
        "    print(f\"Fine-tuned model output: {response.choices[0].text.strip()}\")\n",
        "\n",
        "else:\n",
        "    print(\"Fine-tuning job failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "YQVN_5wydxYa",
        "outputId": "d04268ed-0d3b-46cd-97b7-b149d3c8ea40",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'message': 'The model `ftjob-bDn12IAtDEfENwt8fWeUBOzb` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1598347940.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'succeeded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Step 4: Use the fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     response = client.completions.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfine_tune_id\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# fine-tuned model ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Translate the following English text to French: 'Good night'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_given\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 541\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `ftjob-bDn12IAtDEfENwt8fWeUBOzb` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if status == 'succeeded':\n",
        "  # Step 4: Use the fine-tuned model\n",
        "  response = openai.Completion.create(\n",
        "    model response['fine_tuned_model'],\n",
        "    prompt=\"Translate the following English text to French: 'Good night'\\n\\n###\\n\\n\",\n",
        "    max_tokens=50\n",
        ")\n",
        "  print(f\"Fine-tuned model output: {response.choices [0].text.strip()}\")\n",
        "else:\n",
        "  print(\"Fine-tuning job failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "kwzVCZkpxCml",
        "outputId": "b83d59e0-f407-4f09-8f83-79b59c8e7926",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (ipython-input-1272293865.py, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1272293865.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    model response['fine_tuned_model'],\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "def edit_text(input_text, instruction):\n",
        "  response = openai.Edit.create(\n",
        "    model=\"gpt-4\",\n",
        "    input=input_text,\n",
        "    instruction=instruction\n",
        "  )\n",
        "\n",
        "  return response['choices'][0]['text']\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print(f\"Edited text: {edited_text}\")"
      ],
      "metadata": {
        "id": "sVMlHVgdfdzw",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "fe2f9cfa-3fa8-4410-ed29-c85a8cf80168"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'OPENAI_API_KEY' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4045946276.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOPENAI_API_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0medit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   response = openai.Edit.create(\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OPENAI_API_KEY' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=''"
      ],
      "metadata": {
        "id": "-lAD1PMWLmCg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtRXtGhnLuAp",
        "outputId": "0a42744f-574e-4876-b5fe-23e4f301c5da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.12/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import openai\n",
        "openai .api_key = OPENAI_API_KEY\n",
        "\n",
        "def edit_text(input_text, instruction):\n",
        "  response = openai. Edit.create(\n",
        "    mode1=\"gpt-4\",\n",
        "    input=input_text,\n",
        "    instruction=instruction\n",
        "  )\n",
        "  return response['choices'][0]['message']['content']\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print (f\"Edited text: {edited_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "collapsed": true,
        "id": "uQjF4MbmLGa2",
        "outputId": "51e5e686-4e33-4f2b-ebbf-6faf6c2769f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "Must provide an 'engine' or 'model' parameter to create a <class 'openai.api_resources.edit.Edit'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1943735243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Change 'fox' to 'cat' and change the tense to past.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0medited_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"Edited text: {edited_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1943735243.py\u001b[0m in \u001b[0;36medit_text\u001b[0;34m(input_text, instruction)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0medit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   response = openai. Edit.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmode1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_resources/edit.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__prepare_create_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36m__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 raise error.InvalidRequestError(\n\u001b[0m\u001b[1;32m     91\u001b[0m                     \u001b[0;34m\"Must provide an 'engine' or 'model' parameter to create a %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0;34m%\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: Must provide an 'engine' or 'model' parameter to create a <class 'openai.api_resources.edit.Edit'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai .api_key = OPENAI_API_KEY\n",
        "\n",
        "def edit_text(input_text, instruction):\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\", # Use a supported chat model\n",
        "    messages= [\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant that edits text.\"},\n",
        "      {\"role\": \"user\", \"content\": f\"Please edit the following text: '{input_text}'. Instruction: {instruction}\"}\n",
        "    ]\n",
        "  )\n",
        "  return response['choices'][0]['message']['content']\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print (f\"Edited text: {edited_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHFEZRK8L-C_",
        "outputId": "1e503239-8017-45d5-d0fe-9a26e1481006"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edited text: 'The quick brown cat jumped over the lazy dog.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Function to moderate text using the Moderation API\n",
        "def moderate_text(input_text):\n",
        "  response = openai. Moderation.create(\n",
        "    input=input_text,\n",
        "    model=\"text-moderation-stable\"\n",
        "  )\n",
        "\n",
        "  return response\n",
        "\n",
        "# Example input text\n",
        "input_texts = [\n",
        "  \"I want to harm myself.\",\n",
        "  \"You are an amazing person!\",\n",
        "  \"Let's meet at 8 PM.\",\n",
        "  \"I hate you and I want to hurt you.\"\n",
        "]"
      ],
      "metadata": {
        "id": "3KEZBIA1MtAo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moderate each text and print the results\n",
        "for text in input_texts:\n",
        "  moderation_result = moderate_text(text)\n",
        "  print(f\"Input: {text}\")\n",
        "  print(f\"Moderation Result: {moderation_result}\")\n",
        "  print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "collapsed": true,
        "id": "01niqfEINdva",
        "outputId": "71dcdd95-6fed-4527-8fd0-d8b21126b093"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "please request omni-moderation-latest",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3336116953.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Moderate each text and print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmoderation_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoderate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input: {text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Moderation Result: {moderation_result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3017229068.py\u001b[0m in \u001b[0;36mmoderate_text\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Function to moderate text using the Moderation API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmoderate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   response = openai. Moderation.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-moderation-stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_resources/moderation.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, input, model, api_key)\u001b[0m\n\u001b[1;32m     33\u001b[0m     ):\n\u001b[1;32m     34\u001b[0m         \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/openai_object.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream, plain_old_data, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         )\n\u001b[0;32m--> 179\u001b[0;31m         response, stream, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: please request omni-moderation-latest"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def generate_image(prompt):\n",
        "  response = openai.Image.create(\n",
        "    prompt=prompt,\n",
        "    n=1, # Number of images to generate\n",
        "    size=\"1024x1024\" # Size of the generated image\n",
        "  )\n",
        "\n",
        "  image_url = response['data'][0]['url']\n",
        "  return image_url"
      ],
      "metadata": {
        "id": "Mhe1Usm-NdwZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(image_url, filename):\n",
        "  response = requests.get(image_url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  image.save(filename)\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"A futuristic cityscape at sunset\"\n",
        "\n",
        "# Generate image\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URL: {image_url}\")\n",
        "\n",
        "# Save image to file\n",
        "save_image (image_url, \"generated_image.png\")\n",
        "print(\"Image saved as generated_image.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjD17uLuN9ob",
        "outputId": "e0507ac6-635b-43e1-d632-c97ecdbede58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-1VH9bovdpfXADsGrWTjyoSMJ/user-eNxIyQlrkjy8uNdXwmaiIlSF/img-EJEd1l76mVJumt85WP9nKTio.png?st=2025-12-01T13%3A02%3A00Z&se=2025-12-01T15%3A02%3A00Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=cc612491-d948-4d2e-9821-2683df3719f5&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-12-01T14%3A02%3A00Z&ske=2025-12-02T14%3A02%3A00Z&sks=b&skv=2024-08-04&sig=j32MBY7qYJxR1rz66W70BLn%2Bvt8wcqCsapJtBFFLjj0%3D\n",
            "Image saved as generated_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시바꾸기\n",
        "\n",
        "response = openai.Image.create(\n",
        "model=\"dall-e-3\",\n",
        "prompt=\"a white siamese cat\",\n",
        "size=\"1024x1024\",\n",
        "quality=\"standard\",\n",
        "n=1,\n",
        ")\n",
        "\n",
        "\n",
        "response = client.images.edit(\n",
        "  model=\"dall-e-2\"\n",
        "  image=open(\"sunlit_lounge.png\", \"rb\"),\n",
        "  mask=open(\"mask.png\", \"rb\"),\n",
        "  prompt=\"A sunlit indoor lounge area with a pool containing a flamingo\",\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "\n",
        "image_url = response.data[0].url\n",
        "\n",
        "response = client.images.create_variation(\n",
        "model=\"dall-e-2\",\n",
        "image=open (\"corgi_and_cat_paw.png\", \"rb\"),\n",
        "n=1,\n",
        "size=\"1024x1024\"\n",
        ")\n",
        "image_url = response.data[0].url"
      ],
      "metadata": {
        "id": "6jVmswfPOG3Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "def generate_code(prompt, model=\"gpt-3.5-turbo-instruct\", max_tokens=1000):\n",
        "  try:\n",
        "    response = openai.Completion.create(\n",
        "      model=model,\n",
        "      prompt=prompt,\n",
        "      max_tokens=max_tokens,\n",
        "      temperature=0,\n",
        "      n=1,\n",
        "      stop=None\n",
        "    )\n",
        "\n",
        "    # Extracting the generated code from the response\n",
        "    code = response.choices [0].text.strip()\n",
        "    return code\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "9Mxa8Q3KOitN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt to generate Python code for adding two numbers\n",
        "prompt = \"Write a C code that computes Fibonacci number using memoization.\"\n",
        "\n",
        "# Generate code\n",
        "generated_code = generate_code(prompt)\n",
        "\n",
        "# Print the generated code\n",
        "if generated_code:\n",
        "  print(\"Generated Code:\\n\")\n",
        "  print(generated_code)\n",
        "else:\n",
        "  print(\"Failed to generate code.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oc3NxQyO74o",
        "outputId": "279c8d87-fafa-4b34-b39c-f803f0103162"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "// Function to compute Fibonacci number using memoization\n",
            "int fib(int n, int memo[])\n",
            "{\n",
            "    // Base cases\n",
            "    if (n == 0 || n == 1)\n",
            "        return n;\n",
            "\n",
            "    // Check if the value is already computed\n",
            "    if (memo[n] != -1)\n",
            "        return memo[n];\n",
            "\n",
            "    // Compute and store the value in the memo array\n",
            "    memo[n] = fib(n-1, memo) + fib(n-2, memo);\n",
            "\n",
            "    // Return the computed value\n",
            "    return memo[n];\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    int n;\n",
            "    printf(\"Enter the value of n: \");\n",
            "    scanf(\"%d\", &n);\n",
            "\n",
            "    // Initialize the memo array with -1\n",
            "    int memo[n+1];\n",
            "    for (int i = 0; i <= n; i++)\n",
            "        memo[i] = -1;\n",
            "\n",
            "    // Call the fib function and print the result\n",
            "    printf(\"Fibonacci number at position %d is %d\", n, fib(n, memo));\n",
            "\n",
            "    return 0;\n",
            "}\n",
            "\n",
            "/*\n",
            "Output:\n",
            "\n",
            "Enter the value of n: 6\n",
            "Fibonacci number at position 6 is 8\n",
            "*/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Upload a file\n",
        "upload_response = openai.File.create(\n",
        "  file=open (\"king-style-chat.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "\n",
        "print(\"Upload Response:\")\n",
        "print(upload_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98d1HXQwPEM6",
        "outputId": "f2840f19-a8b2-46ea-f64a-a88e02d47afc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Response:\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-XPM8J2dw1GgMJXGr85o4D4\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 57615,\n",
            "  \"created_at\": 1764598001,\n",
            "  \"expires_at\": null,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files\n",
        "list_response = openai.File.list()\n",
        "print(\"List Response:\")\n",
        "print(list_response)\n",
        "\n",
        "# Retrieve a specific file\n",
        "file_id = upload_response['id']\n",
        "retrieve_response = openai.File.retrieve(file_id)\n",
        "print(\"Retrieve Response:\")\n",
        "print(retrieve_response)\n",
        "\n",
        "# Delete a file\n",
        "delete_response = openai.File.delete(file_id)\n",
        "print(\"Delete Response:\")\n",
        "print(delete_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4vyEghXPNkY",
        "outputId": "8b5c1c43-ec1d-408d-a6de-406d6088df51"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List Response:\n",
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-XPM8J2dw1GgMJXGr85o4D4\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 57615,\n",
            "      \"created_at\": 1764598001,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-LXWynbgf2VXe5bVrnCZYrb\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764597703,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-5U8MqTbyfGb7gn8uZfoFzd\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2200,\n",
            "      \"created_at\": 1764597571,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-R1Vp8zpNzuoGWkgEUWYtxJ\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764596368,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-6aXdLygF4cHr55jvwrxUkS\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2176,\n",
            "      \"created_at\": 1764116351,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-1pmpzB2cmeBN9QuDn9kLwr\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"mydata.jsonl\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764115179,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-X5VCfAYmf5QwqrJPmi9dST\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2176,\n",
            "      \"created_at\": 1764055420,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-NzmfNqoNoUFKuziaG79wfF\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2144,\n",
            "      \"created_at\": 1764054425,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-Bt9rXyk72KMQZpBMw393xR\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2192,\n",
            "      \"created_at\": 1764054403,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-RudbXWP247r3pggQf8PsKk\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2160,\n",
            "      \"created_at\": 1764054385,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-5yuwuc6evqkppxbnb5wFoD\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"mydata.jsonl\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764053192,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-BPnc2tj7vxBDL5hG9YZDxE\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764052410,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-Ec2Q5zgHGpLX2qwZ2AWs91\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 2144,\n",
            "      \"created_at\": 1764047341,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-UVxgpJEvxF2hRndseF9jeb\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764046327,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-CS5RryVCVV5dv1yy2P2Equ\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1764045993,\n",
            "      \"expires_at\": null,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"has_more\": false,\n",
            "  \"first_id\": \"file-XPM8J2dw1GgMJXGr85o4D4\",\n",
            "  \"last_id\": \"file-CS5RryVCVV5dv1yy2P2Equ\"\n",
            "}\n",
            "Retrieve Response:\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-XPM8J2dw1GgMJXGr85o4D4\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 57615,\n",
            "  \"created_at\": 1764598001,\n",
            "  \"expires_at\": null,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n",
            "Delete Response:\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"deleted\": true,\n",
            "  \"id\": \"file-XPM8J2dw1GgMJXGr85o4D4\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Function to transcribe audio using OpenAI Audio API\n",
        "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\", temperature=0.1, language=None, prompt=None):\n",
        "  with open (file_path, \"rb\") as audio_file:\n",
        "    response = openai.Audio.transcribe(\n",
        "      file=audio_file,\n",
        "      model=model,\n",
        "      response_format=response_format,\n",
        "      temperature=temperature,\n",
        "      language=language,\n",
        "      prompt=prompt\n",
        "    )\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "NS5pupiJPQkT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example file path\n",
        "file_path = 'Dracula.mp3'\n",
        "\n",
        "# Transcribe the audio file\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC0yBsIkPY4-",
        "outputId": "0bb5626d-f286-4a8a-bd26-97683ceacee1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response:\n",
            "{\n",
            "  \"text\": \"Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse, the candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders, searching for some precious grail. We are the embers that glow in the winter, the diamonds in the mine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds. When the great battle commences, surely the light will prevail. We will break down his defenses, he will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds.\",\n",
            "  \"usage\": {\n",
            "    \"type\": \"duration\",\n",
            "    \"seconds\": 116\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}
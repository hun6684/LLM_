{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoPvcRVpMlEPPV+lMXnFit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hun6684/LLM_/blob/main/%EC%A7%80%EB%8A%A5%ED%98%95%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bQrvMrjCLtKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a400493d-1829-4cf1-dca9-6954a1039701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file-WWLqozNsqbH3omYKBXxBGs\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=''\n",
        "  file=open(\"zzanggu_finetune.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(myfile.id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myjob = client.fine_tuning.jobs.create(\n",
        "  training_file=myfile.id,\n",
        "  model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "print(myjob.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0zRVkJOOzQL",
        "outputId": "1566f257-7b3c-4ec8-c766-49748d82e182"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ftjob-rF8iykvK13fmPEsamd5mlPXV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(myjob.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoPQVsCVO5cT",
        "outputId": "af196a83-92d5-4be8-9d1f-6c87ac855df1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validating_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.retrieve(myjob.id)\n",
        "if job.status == 'succeeded':\n",
        "  fine_tuned_model_id = job.fine_tuned_model\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "      model=fine_tuned_model_id, # Use the correct model ID\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also humorous.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What's the capital of Richtenstein?\"}\n",
        "      ]\n",
        "\n",
        ")\n",
        "  print(completion.choices[0].message.content)\n",
        "else:\n",
        "  print(\"Fine-tuning job is still in progress. Please wait and try again later.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq52BLP4O_1L",
        "outputId": "12de5ab6-89dc-4e47-900a-817e33e213df"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning job is still in progress. Please wait and try again later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_id = \"ft:gpt-3.5-turbo-0125:personal::CmzaU12u\"\n",
        "model_id = \"gpt-3.5-turbo-0125\""
      ],
      "metadata": {
        "id": "1-NCl8KEPDfC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a general model for chat completion\n",
        "completion = client.chat.completions.create(\n",
        "  model=model_id, # Use the correct model ID\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"짱구의 말투를 사용하여 답장하시오.\"},\n",
        "    {\"role\": \"user\", \"content\": \"오늘 점심은 뭐 먹을래?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices [0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC32V14cPJPR",
        "outputId": "15956178-1c1a-48cf-acfb-bb80f56084a8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "역시 멋진 나 그리고 좋은 너가 함께 먹고 싶은 걸 먹을텐데, 뭐가 좋을까? 혹시 너가 원하는 메뉴 있어?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the fine-tuned model for chat completion\n",
        "completion = client.chat.completions.create(\n",
        "  model=fine_tuned_model_id, # Use the correct model ID\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"짱구의 말투를 사용하여 답장하시오.\"},\n",
        "    {\"role\": \"user\", \"content\": \"오늘 점심은 뭐 먹을래?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRo263p7PVVv",
        "outputId": "5423ece5-c6b8-4f0a-cf2f-986861a3d61a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "짱구는 교칙 위반! 과자 먹을 거지롱~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a general model for chat completion\n",
        "completion = client.chat.completions.create(\n",
        "  model=model_id, # Use the correct model ID\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"짱구의 말투를 사용하여 답장하시오.\"},\n",
        "    {\"role\": \"user\", \"content\": \"고양이들끼리 안 싸워요?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices [0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h371DdFagcNT",
        "outputId": "c74bdf6d-5f6f-4cf7-df06-468c289a54b9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그건 아니에요! 고양이들끼리 싸우기도 하지만 친해지면 잘 지낼 수도 있어요. 혼자 둬도 습니까? 둘이서 훨씬 더 즐겁지 않아요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the fine-tuned model for chat completion\n",
        "completion = client.chat.completions.create(\n",
        "  model=fine_tuned_model_id, # Use the correct model ID\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"짱구의 말투를 사용하여 답장하시오.\"},\n",
        "    {\"role\": \"user\", \"content\": \"고양이들끼리 안 싸워요?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCIyFw6Xggn3",
        "outputId": "f8c91f52-0f0e-4981-ae8a-4391735c4ef6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "짱구네 집에는 가족끼리도 종종 싸움이 있지! 아마도 몰아내기 전투가 치열할 듯 해~\n"
          ]
        }
      ]
    }
  ]
}